import os
import faiss
import numpy as np
import pandas as pd
import configparser
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.in_memory import InMemoryDocstore
from langchain_community.vectorstores.faiss import FAISS
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings

# üîß Normalized embedding wrapper for cosine similarity
class NormalizedAzureOpenAIEmbeddings(AzureOpenAIEmbeddings):
    def embed_documents(self, texts):
        vectors = super().embed_documents(texts)
        return [self._normalize(vec) for vec in vectors]

    def embed_query(self, text):
        vector = super().embed_query(text)
        return self._normalize(vector)

    def _normalize(self, vec):
        norm = np.linalg.norm(vec)
        return (np.array(vec) / norm).tolist() if norm > 0 else vec

# Parameters
TOP_K = 5

# Load config.ini
config = configparser.ConfigParser()
config.read("config.ini")

# Azure config
AZURE_OPENAI_API_KEY = config["azure_openai"]["api_key"]
AZURE_OPENAI_ENDPOINT = config["azure_openai"]["endpoint"]
AZURE_OPENAI_API_VERSION = config["azure_openai"]["api_version"]
EMBEDDING_DEPLOYMENT = config["embedding_models"]["text_embedding_3_large"]
EMBEDDING_MODEL = "text-embedding-3-large"
GPT_DEPLOYMENT = config["gpt_models"]["model_gpt4o"]

# Load CSV
csv_path = r"d2c1f46e2b3267d315fb03f76724aa7036ea01b3f1803e94126e26dc26881629.csv"
df = pd.read_csv(csv_path)

# Convert to LangChain Documents
documents = []
for _, row in df.iterrows():
    if pd.isna(row["text"]):
        continue
    documents.append(Document(
        page_content=row["text"],
        metadata={"source": row["title"]}
    ))

# Chunk documents
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=250)
chunks = splitter.split_documents(documents)

# Embedding model (normalized)
embedding_model = NormalizedAzureOpenAIEmbeddings(
    deployment=EMBEDDING_DEPLOYMENT,
    model=EMBEDDING_MODEL,
    openai_api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    openai_api_version=AZURE_OPENAI_API_VERSION,
    chunk_size=1000
)

# Embed and build FAISS index
texts = [doc.page_content for doc in chunks]
embeddings = embedding_model.embed_documents(texts)
embeddings = np.array(embeddings).astype("float32")

index = faiss.IndexFlatIP(embeddings.shape[1])  # cosine similarity
index.add(embeddings)

# Build docstore & index mapping
docstore = InMemoryDocstore({str(i): chunks[i] for i in range(len(chunks))})
index_to_docstore = {i: str(i) for i in range(len(chunks))}

# Vector store with cosine similarity
vectorstore = FAISS(embedding_model, index, chunks, index_to_docstore, docstore)
vectorstore.save_local("faiss_index_cosine")

# Query
query = "Based on the clinical note, what medications has the patient received, and what is the current status of those treatments?"
top_results = vectorstore.similarity_search_with_score(query, k=TOP_K)
docs_only = [doc for doc, _ in top_results]

# LLM
llm = AzureChatOpenAI(
    deployment_name=GPT_DEPLOYMENT,
    model_name="gpt-4o",
    openai_api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    openai_api_version=AZURE_OPENAI_API_VERSION,
    temperature=0
)

# Prompt
context = "\n\n".join([doc.page_content for doc in docs_only])
full_prompt = f"""
You are a clinical assistant specialized in analyzing oncology patient records.
Your task is to read the provided clinical notes and answer the medical question based only on the given context.
If the answer is not found in the context, respond with \"Not mentioned in the context.\"

---
üìÑ Context:
{context}

---
‚ùì Question:
{query}
"""

# Run LLM
response = llm.invoke(full_prompt)

# Output
print(f"\nüìò Answer:\n{response.content}")
print(f"\nüîç Top {TOP_K} Retrieved Chunks with Cosine Similarity:\n")

for i, (doc, score) in enumerate(top_results):
    print(f"--- [Chunk {i+1}] from Document: {doc.metadata['source']} ---")
    print(f"üîó Cosine Similarity Score: {score:.4f}")
    print(doc.page_content)
    print("-" * 100)
