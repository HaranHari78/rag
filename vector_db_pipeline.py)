import os
import pandas as pd
import configparser
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import AzureOpenAIEmbeddings
from langchain.chat_models import AzureChatOpenAI
from langchain.chains import RetrievalQA

# Load config
config = configparser.ConfigParser()
config.read("config.ini")

# Azure settings
AZURE_OPENAI_API_KEY = config["azure_openai"]["api_key"]
AZURE_OPENAI_ENDPOINT = config["azure_openai"]["endpoint"]
AZURE_OPENAI_API_VERSION = config["azure_openai"]["api_version"]
EMBEDDING_DEPLOYMENT = config["embedding_models"]["text_embedding_3_large"]
EMBEDDING_MODEL = "text-embedding-3-large"
GPT_DEPLOYMENT = config["gpt_models"]["model_gpt4o"]

# Step 1: Load data
df = pd.read_csv(r"C:\Users\HariharaM12\Downloads\Medical_Data.csv")  # CSV with 'title' and 'text'
documents = []

# Step 2: Create LangChain Document objects with metadata
for _, row in df.iterrows():
    if pd.isna(row["text"]):
        continue
    documents.append(Document(
        page_content=row["text"],
        metadata={"source": row["title"]}
    ))

# Step 3: Split into chunks
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(documents)

# Step 4: Azure OpenAI Embedding model
embedding_model = AzureOpenAIEmbeddings(
    deployment=EMBEDDING_DEPLOYMENT,
    model=EMBEDDING_MODEL,
    openai_api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    openai_api_version=AZURE_OPENAI_API_VERSION
)

# Step 5: Build FAISS vector DB
vectorstore = FAISS.from_documents(chunks, embedding_model)
vectorstore.save_local("faiss_index")  # Save to disk

# Step 6: RetrievalQA chain using GPT model (optional)
llm = AzureChatOpenAI(
    deployment_name=GPT_DEPLOYMENT,
    model_name="gpt-4o",
    openai_api_version=AZURE_OPENAI_API_VERSION,
    openai_api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    temperature=0
)

retriever = vectorstore.as_retriever()
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True
)

# Step 7: Ask a question
query = "What diagnosis is mentioned in the document?"
response = qa_chain({"query": query})

print("ðŸ“˜ Answer:", response["result"])
print("ðŸ“Ž Sources:", [doc.metadata["source"] for doc in response["source_documents"]])
