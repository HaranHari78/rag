import os
import json
import re
import pandas as pd
from kappa_prompt import build_kappa_lambda_prompt
from utils import load_config, call_openai_api

# --- PATHS ---
input_dir = r"C:\Users\HariharaM12\PycharmProjects\Med_Data\output\sentences"
output_json = r"C:\Users\HariharaM12\PycharmProjects\Med_Data\output\fields\kappa_lambda_ratio_grouped.json"
output_excel = r"C:\Users\HariharaM12\PycharmProjects\Med_Data\output\fields\kappa_lambda_ratio_result.xlsx"
os.makedirs(os.path.dirname(output_json), exist_ok=True)

# --- MODEL CONFIG ---
config = load_config()
model = config['gpt_models']['model_gpt4o']

# --- CLEAN JSON WRAPPER ---
def clean_response(resp: str) -> str:
    return re.sub(r'```(?:json)?\n?|\n?```', '', resp).strip()

# --- FINAL RESULTS ---
results = []

all_files = sorted([f for f in os.listdir(input_dir) if f.endswith(".json")])
for filename in all_files:
    path = os.path.join(input_dir, filename)
    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    doc_title = data.get("document_title", filename)
    lab_sentences = data.get("lab_result_sentences", [])
    if not lab_sentences:
        continue

    prompt = build_kappa_lambda_prompt(" ".join(lab_sentences), doc_title)
    response = call_openai_api(prompt, model)

    if not response:
        print(f"âŒ No response: {doc_title}")
        continue

    try:
        raw = clean_response(response)
        parsed = json.loads(raw)
        results.append(parsed)
        print(f"âœ… Extracted: {doc_title}")
    except Exception as e:
        print(f"âš ï¸ JSON error: {doc_title} â†’ {e}")

# --- SAVE JSON OUTPUT ---
with open(output_json, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=4)
print(f"\nðŸ“ JSON saved â†’ {output_json}")

# --- FLATTEN + SAVE EXCEL ---
flattened = []
for entry in results:
    flat = {
        "document_title": entry.get("document_title", ""),
        "kappa_value": entry["kappa_flc"]["value"],
        "kappa_date": entry["kappa_flc"]["date"],
        "kappa_evidence": entry["kappa_flc"]["evidence"],
        "lambda_value": entry["lambda_flc"]["value"],
        "lambda_date": entry["lambda_flc"]["date"],
        "lambda_evidence": entry["lambda_flc"]["evidence"],
        "ratio_value": entry["kappa_lambda_ratio"]["value"],
        "ratio_date": entry["kappa_lambda_ratio"]["date"],
        "ratio_evidence": entry["kappa_lambda_ratio"]["evidence"]
    }
    flattened.append(flat)

df_final = pd.DataFrame(flattened)

# Drop duplicates based on values and evidence
df_final.drop_duplicates(
    subset=["kappa_value", "lambda_value", "ratio_value", "kappa_evidence", "lambda_evidence", "ratio_evidence"],
    inplace=True
)

# Save to Excel
df_final.to_excel(output_excel, index=False)
print(f"ðŸ“Š Excel saved â†’ {output_excel}")



# kappa_prompt.py

def build_kappa_lambda_prompt(text: str, doc_title: str) -> str:
    return f"""
You are a medical AI assistant. Extract the following from clinical notes:

ðŸ§ª Fields to extract:
1. `kappa_flc`: numerical value + unit (prefer mg/dL or mg/L)
2. `lambda_flc`: numerical value + unit (prefer mg/dL or mg/L)
3. `kappa_lambda_ratio`: the reported ratio (may include > or <)

For each field, also extract:
- `date`: exact date if present. 
    ðŸ”¹ If the date is partial (e.g., only year or year+month), fill missing parts with "XX".
    ðŸ”¹ Example: "2022-05" â†’ "2022-05-XX", "2022" â†’ "2022-XX-XX"
    ðŸ”¹ â— DO NOT infer or guess dates.

- `evidence`: exact sentence or phrase from the note (verbatim)

ðŸ“„ Document Title: {doc_title}

ðŸ’¡ Rules:
- Use only values with proper units like "mg/dL", "mg/L"
- If multiple values found, prefer the one that has all 3: kappa, lambda, and ratio
- Use the sentence containing all 3 as the evidence if possible

ðŸ§¾ Text:
\"\"\"{text}\"\"\"

Return your response as JSON:
{{
  "document_title": "{doc_title}",
  "kappa_flc": {{"value": "", "date": "", "evidence": ""}},
  "lambda_flc": {{"value": "", "date": "", "evidence": ""}},
  "kappa_lambda_ratio": {{"value": "", "date": "", "evidence": ""}}
}}
"""
