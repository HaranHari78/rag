import os
import json
import re
import pandas as pd
from kappa_prompt import build_kappa_lambda_prompt
from utils import load_config, call_openai_api

# --- PATHS ---
input_dir = r"C:\Users\HariharaM12\PycharmProjects\Med_Data\output\sentences"
output_json = r"C:\Users\HariharaM12\PycharmProjects\Med_Data\output\fields\kappa_lambda_ratio_grouped.json"
output_excel = r"C:\Users\HariharaM12\PycharmProjects\Med_Data\output\fields\kappa_lambda_ratio_result.xlsx"
os.makedirs(os.path.dirname(output_json), exist_ok=True)

# --- MODEL CONFIG ---
config = load_config()
model = config['gpt_models']['model_gpt4o']

# --- CLEAN JSON WRAPPER ---
def clean_response(resp: str) -> str:
    return re.sub(r'```(?:json)?\n?|\n?```', '', resp).strip()

# --- BATCH RANGE ---
start_index = 0
end_index = 100  # Process only files in this range

# --- FINAL RESULTS ---
results = []

all_files = sorted([f for f in os.listdir(input_dir) if f.endswith(".json")])
batch_files = all_files[start_index:end_index]

for filename in batch_files:
    path = os.path.join(input_dir, filename)
    with open(path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    doc_title = data.get("document_title", filename)
    lab_sentences = data.get("lab_result_sentences", [])
    if not lab_sentences:
        continue

    prompt = build_kappa_lambda_prompt(" ".join(lab_sentences), doc_title)
    response = call_openai_api(prompt, model)

    if not response:
        print(f"âŒ No response: {doc_title}")
        continue

    try:
        raw = clean_response(response)
        parsed = json.loads(raw)
        results.append(parsed)
        print(f"âœ… Extracted: {doc_title}")
    except Exception as e:
        print(f"âš ï¸ JSON error: {doc_title} â†’ {e}")

# --- SAVE JSON OUTPUT ---
with open(output_json, 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=4)
print(f"\nğŸ“ JSON saved â†’ {output_json}")

# --- FLATTEN + SAVE EXCEL ---
flattened = []
for entry in results:
    flat = {
        "document_title": entry.get("document_title", ""),
        "kappa_value": entry["kappa_flc"]["value"],
        "kappa_date": entry["kappa_flc"]["date"],
        "kappa_evidence": entry["kappa_flc"]["evidence"],
        "lambda_value": entry["lambda_flc"]["value"],
        "lambda_date": entry["lambda_flc"]["date"],
        "lambda_evidence": entry["lambda_flc"]["evidence"],
        "ratio_value": entry["kappa_lambda_ratio"]["value"],
        "ratio_date": entry["kappa_lambda_ratio"]["date"],
        "ratio_evidence": entry["kappa_lambda_ratio"]["evidence"]
    }
    flattened.append(flat)

df_final = pd.DataFrame(flattened)

# Drop duplicates based on value and evidence fields
df_final.drop_duplicates(
    subset=[
        "kappa_value", "lambda_value", "ratio_value",
        "kappa_evidence", "lambda_evidence", "ratio_evidence"
    ],
    inplace=True
)

# Save to Excel
df_final.to_excel(output_excel, index=False)
print(f"ğŸ“Š Excel saved â†’ {output_excel}")



SEN_PROMPT::



def build_kappa_lambda_sentence_prompt(text: str) -> str:
    return f"""
You are a medical AI assistant.

Extract only those **verbatim sentences** from the clinical note that mention any of the following:

1. Kappa Free Light Chains â€” values with proper unit (mg/dL or mg/L)
2. Lambda Free Light Chains â€” values with proper unit (mg/dL or mg/L)
3. Kappa/Lambda Ratio â€” numerical ratio values, optionally with signs like ">", "<"

ğŸ§ª For each extracted sentence:
- The sentence **must** include at least one of the above values clearly.
- Do not extract repeated or paraphrased duplicates â€” **only one instance** per field per document.
- Prefer sentences that include **all three fields** (kappa, lambda, ratio) together, if available.

ğŸ“… Date Extraction Rules:
- If the sentence includes a date (e.g., test date), retain it.
- If the date is partial (like "2022-05"), fill the missing part with `"XX"`, e.g.,:
  ğŸ”¹ "2022-05" â†’ `"2022-05-XX"`  
  ğŸ”¹ "2022" â†’ `"2022-XX-XX"`
- â—Never guess or infer missing dates.

ğŸ“„ Input Clinical Note:
\"\"\"{text}\"\"\"

Return your output strictly in the following JSON format:
{{
  "kappa_lambda_lab_sentences": [
    "..."
  ]
}}
"""



FIELD_PROMPT::


def build_kappa_lambda_field_prompt(text: str, doc_title: str) -> str:
    return f"""
You are a medical AI assistant trained to extract structured lab values related to Free Light Chain assays from clinical note sentences.

ğŸ“„ Document Title: {doc_title}

ğŸ” Your job:
From the input text, extract the following fields **only if the value and unit are explicitly present**:

1. `kappa_flc`: numerical value (e.g., 0.08) + unit (e.g., mg/dL or mg/L)
2. `lambda_flc`: numerical value + unit (mg/dL or mg/L)
3. `kappa_lambda_ratio`: the reported ratio, optionally with symbols like > or < (e.g., ">0.57")

ğŸ—“ï¸ For each field, also extract:
- `date`: exact date associated with the test (if present in the sentence)
    ğŸ”¹ If the date is partial (e.g., only year or year+month), fill missing parts with "XX".
    ğŸ”¹ Example: "2022-05" â†’ "2022-05-XX", "2022" â†’ "2022-XX-XX"
    ğŸ”¹ â— Do not guess or infer the date â€” extract it only if explicitly mentioned.
- `evidence`: the **verbatim sentence** from which the value was extracted

ğŸ“Œ Additional Instructions:
- Use only values with **mg/dL or mg/L** units â€” ignore unitless or ambiguous mentions.
- If multiple values are found:
    ğŸ”¹ Prefer the one that contains all three fields together.
    ğŸ”¹ Otherwise, use the **most informative sentence** per field.
- â—Avoid duplication â€” each field should appear only once in the output.

ğŸ§¾ Input Text:
\"\"\"{text}\"\"\"

ğŸ“¤ Return your response in the following strict JSON format:
{{
  "document_title": "{doc_title}",
  "kappa_flc": {{
    "value": "", "date": "", "evidence": ""
  }},
  "lambda_flc": {{
    "value": "", "date": "", "evidence": ""
  }},
  "kappa_lambda_ratio": {{
    "value": "", "date": "", "evidence": ""
  }}
}}
"""
