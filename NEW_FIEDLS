Error for document 2024-02-08_00:00:00.000_Progress_Notes_91427: Expecting value: line 1 column 1 (char 0)
Error for document 2024-04-17_00:00:00.000_IMTX_Conference_Note_91586: Expecting value: line 1 column 1 (char 0)
Error for document 2024-04-17_00:00:00.000_Progress_Notes_91591: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "C:\Users\HariharaM12\PycharmProjects\Task2\main.py", line 117, in <module>
    result_df = result_df[cols]
                ~~~~~~~~~^^^^^^
  File "C:\Users\HariharaM12\PycharmProjects\Task2\.venv\Lib\site-packages\pandas\core\frame.py", line 4113, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\HariharaM12\PycharmProjects\Task2\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 6212, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "C:\Users\HariharaM12\PycharmProjects\Task2\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 6261, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['source_document', 'kappa_light_chain_mg_per_dl',\n       'lambda_light_chain_mg_per_dl', 'kappa_lambda_ratio'],\n      dtype='object')] are in the [columns]"

Process finished with exit code 1



import os
import re
import json
import pandas as pd
import configparser
import faiss
import numpy as np
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI

# Load config
config = configparser.ConfigParser()
config.read("config.ini")

# Azure credentials
AZURE_OPENAI_API_KEY = config["azure_openai"]["api_key"]
AZURE_OPENAI_ENDPOINT = config["azure_openai"]["endpoint"]
AZURE_OPENAI_API_VERSION = config["azure_openai"]["api_version"]
EMBEDDING_DEPLOYMENT = config["embedding_models"]["text_embedding_3_large"]
EMBEDDING_MODEL = "text-embedding-3-large"
GPT_DEPLOYMENT = config["gpt_models"]["model_gpt4o"]

# Load clinical CSV
csv_path = "MEDICAL_DATAS.csv"
df = pd.read_csv(csv_path)

# Create Documents
documents = []
for _, row in df.iterrows():
    if pd.isna(row["text"]):
        continue
    documents.append(Document(page_content=row["text"], metadata={"source": row["title"]}))

# Split with smart overlap
splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
chunks = splitter.split_documents(documents)

# Embed
embedding_model = AzureOpenAIEmbeddings(
    deployment=EMBEDDING_DEPLOYMENT,
    model=EMBEDDING_MODEL,
    openai_api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    openai_api_version=AZURE_OPENAI_API_VERSION,
    chunk_size=1000
)

texts = [chunk.page_content for chunk in chunks]
metadatas = [chunk.metadata for chunk in chunks]
embeddings = embedding_model.embed_documents(texts)
embeddings = np.array(embeddings).astype("float32")
faiss.normalize_L2(embeddings)

index = faiss.IndexFlatIP(embeddings.shape[1])
index.add(embeddings)

# Prompt template
query_template = {
    "instruction": "Extract values for the following fields related to Free Light Chains. Respond in strict JSON format.",
    "fields": [
        "kappa_light_chain_mg_per_dl",
        "lambda_light_chain_mg_per_dl",
        "kappa_lambda_ratio"
    ]
}

llm = AzureChatOpenAI(
    deployment_name=GPT_DEPLOYMENT,
    model_name="gpt-4o",
    openai_api_key=AZURE_OPENAI_API_KEY,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    openai_api_version=AZURE_OPENAI_API_VERSION,
    temperature=0
)

final_results = []
TOP_K = 4

for doc in documents:
    query_embedding = embedding_model.embed_query("Free light chain levels")
    query_embedding = np.array([query_embedding]).astype("float32")
    faiss.normalize_L2(query_embedding)
    D, I = index.search(query_embedding, TOP_K)

    context_chunks = [chunks[i].page_content for i in I[0] if chunks[i].metadata["source"] == doc.metadata["source"]]
    if not context_chunks:
        continue

    context = "\n\n".join(context_chunks)
    full_prompt = f"""
You are a clinical assistant analyzing oncology lab results.
Extract the following values ONLY if explicitly mentioned in the context. If not present, write null.
Respond in strict JSON like:
{{
  \"kappa_light_chain_mg_per_dl\": \"0.09 mg/dL\",
  \"lambda_light_chain_mg_per_dl\": \"0.15 mg/dL\",
  \"kappa_lambda_ratio\": \"0.60\"
}}

---
Context:
{context}
---
"""
    try:
        response = llm.invoke(full_prompt)
        data = json.loads(response.content)
        data["source_document"] = doc.metadata["source"]
        final_results.append(data)
    except Exception as e:
        print(f"Error for document {doc.metadata['source']}: {e}")

# Convert and reorder columns
result_df = pd.DataFrame(final_results)
cols = ["source_document", "kappa_light_chain_mg_per_dl", "lambda_light_chain_mg_per_dl", "kappa_lambda_ratio"]
result_df = result_df[cols]

# Remove duplicate rows based on all relevant value columns
result_df.drop_duplicates(subset=cols, inplace=True)

# Output path
output_dir = r"C:\\Users\\HariharaM12\\PycharmProjects\\Rag1\\Task"
os.makedirs(output_dir, exist_ok=True)
output_path = os.path.join(output_dir, "extracted_results.xlsx")

# Save to Excel
result_df.to_excel(output_path, index=False)
print(f"âœ… Extraction complete. Output saved to {output_path}")
